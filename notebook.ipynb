{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.lax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rts.config import EnvConfig\n",
    "from src.rts.env import Board, EnvState, init_state, move, reinforce_troops\n",
    "from src.rts.utils import assert_valid_state, get_legal_moves, fixed_argwhere\n",
    "\n",
    "from src.rts.visualizaiton import visualize_board\n",
    "\n",
    "from src.main import step, batched_step, p1_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a game with random moves for 1000 steps\n",
    "# Visualize the board interactivly\n",
    "rng_key = jax.random.PRNGKey(3)\n",
    "config = EnvConfig(\n",
    "    board_width = 10,\n",
    "    board_height = 10,\n",
    "    num_neutral_bases = 6,\n",
    "    num_neutral_troops_start = 10,\n",
    "    neutral_troops_min = 4,\n",
    "    neutral_troops_max = 10,\n",
    "    player_start_troops=5,\n",
    "    bonus_time=10,\n",
    ")\n",
    "state = init_state(rng_key, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    rng_key, subkey = jax.random.split(rng_key)\n",
    "    state, p1_reward = step(state, subkey, config)\n",
    "    assert_valid_state(state)\n",
    "    if i % 1 == 0:\n",
    "        visualize_board(state)\n",
    "    print(p1_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax import nnx\n",
    "import optax\n",
    "\n",
    "class Model(nnx.Module):\n",
    "  def __init__(self, in_dim, mid_dim, out_dim, rngs: nnx.Rngs):\n",
    "    self.lin_in = nnx.Linear(in_dim, mid_dim, rngs=rngs)\n",
    "    self.layer_norm = nnx.LayerNorm(mid_dim, rngs=rngs)\n",
    "    self.lin_out = nnx.Linear(mid_dim, out_dim, rngs=rngs)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = nnx.relu(self.layer_norm(self.lin_in(x)))\n",
    "    return self.lin_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.PRNGKey(3)\n",
    "width = 6\n",
    "height = 6\n",
    "config = EnvConfig(\n",
    "    board_width = width,\n",
    "    board_height = height,\n",
    "    num_neutral_bases = 3,\n",
    "    num_neutral_troops_start = 5,\n",
    "    neutral_troops_min = 4,\n",
    "    neutral_troops_max = 10,\n",
    "    player_start_troops=5,\n",
    "    bonus_time=10,\n",
    ")\n",
    "model = Model(width*height*4, 256, width*height*4, rngs=nnx.Rngs(0))\n",
    "\n",
    "state = init_state(rng_key, config)\n",
    "for i in range(500):\n",
    "    flat_state = jnp.array(state.board.flatten())\n",
    "    legal_mask = get_legal_moves(state, 0)\n",
    "    legal_mask = jnp.array(legal_mask.flatten())\n",
    "    action = jnp.argmax((model(flat_state) + 10) * legal_mask)\n",
    "    # split action from int to array\n",
    "    # y, x, direction\n",
    "    action = jnp.array([action // (width*4), (action % (width*4))//4, action % 4])\n",
    "    rng_key, subkey = jax.random.split(rng_key)\n",
    "    state, p1_reward = p1_step(state, subkey, config, action)\n",
    "    assert_valid_state(state)\n",
    "    if i % 5 == 0:\n",
    "        visualize_board(state)\n",
    "    print(p1_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we vmap\n",
    "N = 50\n",
    "rng_key = jax.random.PRNGKey(3)\n",
    "rng_keys = jax.random.split(rng_key, N)\n",
    "\n",
    "# Create the initial state for each game via vmap.\n",
    "batched_init_state = jax.vmap(lambda key: init_state(key, config))\n",
    "states = batched_init_state(rng_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5000):\n",
    "    # For each parallel game, split its RNG key into two:\n",
    "    # keys_split will have shape (N, 2, key_shape).\n",
    "    keys_split = jax.vmap(lambda key: jax.random.split(key, 2))(rng_keys)\n",
    "    # Update rng_keys to the first half and use the second half as subkeys.\n",
    "    rng_keys = keys_split[:, 0]\n",
    "    subkeys = keys_split[:, 1]\n",
    "\n",
    "    # Take one step in parallel for all games.\n",
    "    states, p1_rewards = batched_step(states, subkeys, config)\n",
    "\n",
    "    # Visualize and validate\n",
    "    if i % 250 == 0:\n",
    "        print(p1_rewards)\n",
    "        board = Board(\n",
    "            player_1_troops = states.board.player_1_troops[79],\n",
    "            player_2_troops = states.board.player_2_troops[79],\n",
    "            neutral_troops = states.board.neutral_troops[79],\n",
    "            bases = states.board.bases[79],\n",
    "        )\n",
    "        single_state = EnvState(board = board)\n",
    "        assert_valid_state(single_state)\n",
    "        visualize_board(single_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def time_block(label: str, timing_dict: dict[str, float]):\n",
    "    start_time = time.time()\n",
    "    yield\n",
    "    end_time = time.time()\n",
    "    timing_dict[label] = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Params:\n",
    "    num_iterations: int\n",
    "    lr: float\n",
    "    gamma: float\n",
    "    q_lambda: float\n",
    "    num_envs: int\n",
    "    num_steps: int\n",
    "    update_epochs: int\n",
    "    num_minibatches: int\n",
    "    epsilon: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    num_iterations=6,\n",
    "    lr=6e-4,\n",
    "    gamma=0.99,\n",
    "    q_lambda=0.65,\n",
    "    num_envs=2048,\n",
    "    num_steps=26,\n",
    "    update_epochs=4,\n",
    "    num_minibatches=4,\n",
    "    epsilon=0.25,\n",
    ")\n",
    "q_net = Model(width*height*4, 256, width*height*4, rngs=nnx.Rngs(0))\n",
    "optimizer = nnx.Optimizer(q_net, optax.adam(params.lr))\n",
    "\n",
    "# @functools.partial(jax.jit, static_argnums=(0,))\n",
    "def single_rollout(rng_key, config: EnvConfig, model: Model, params: Params):\n",
    "    state = init_state(rng_key, config)\n",
    "    \n",
    "    def policy_step(carry, _):\n",
    "        state, rng_key, cum_reward = carry\n",
    "        \n",
    "        flat_state = jnp.array(state.board.flatten())\n",
    "        legal_mask = jnp.array(get_legal_moves(state, 0).flatten())\n",
    "        \n",
    "        logits = model(flat_state) + 10\n",
    "        action = jnp.argmax(logits * legal_mask)\n",
    "        \n",
    "        # Split the scalar action into (row, col, direction) components.\n",
    "        action_split = jnp.array([\n",
    "            action // (config.board_width * 4),\n",
    "            (action % (config.board_width * 4)) // 4,\n",
    "            action % 4\n",
    "        ])\n",
    "        \n",
    "        rng_key, subkey = jax.random.split(rng_key)\n",
    "        next_state, p1_reward = p1_step(state, subkey, config, action_split)\n",
    "        \n",
    "        new_cum_reward = cum_reward + p1_reward\n",
    "        \n",
    "        # The buffer (y) collects: observation (state.board), action, reward, next observation.\n",
    "        y = (state.board, action, p1_reward, next_state.board)\n",
    "        \n",
    "        # The new carry is the updated state, RNG key, and cumulative reward.\n",
    "        return (next_state, rng_key, new_cum_reward), y\n",
    "\n",
    "    (final_state, final_rng, cum_return), scan_out = jax.lax.scan(\n",
    "        policy_step,\n",
    "        (state, rng_key, jnp.array(0.0)),\n",
    "        None,\n",
    "        params.num_steps\n",
    "    )\n",
    "    obs_buffer, actions_buffer, rewards_buffer, next_obs_buffer = scan_out\n",
    "    return obs_buffer, actions_buffer, rewards_buffer, next_obs_buffer, cum_return\n",
    "\n",
    "obs_buffer, actions_buffer, rewards_buffer, next_obs_buffer, cum_return = single_rollout(rng_key, config, q_net, params)\n",
    "rewards_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
